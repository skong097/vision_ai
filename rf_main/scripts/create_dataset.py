"""
ë°ì´í„°ì…‹ ìƒì„± - Train/Val/Test Split (Binary & 3-Class)
Author: Home Safe Solution Team
Date: 2026-01-28
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')


class DatasetCreator:
    """Train/Val/Test ë°ì´í„°ì…‹ ìƒì„±"""
    
    def __init__(self, labeled_dir, output_dir):
        self.labeled_dir = Path(labeled_dir)
        self.output_dir = Path(output_dir)
        
        # Binary & 3-Class ë³„ë„ ë””ë ‰í† ë¦¬
        self.binary_dir = self.output_dir / 'binary'
        self.class3_dir = self.output_dir / '3class'
        
        self.binary_dir.mkdir(parents=True, exist_ok=True)
        self.class3_dir.mkdir(parents=True, exist_ok=True)
    
    def get_feature_columns(self, df):
        """Feature ì»¬ëŸ¼ ì„ íƒ (ë¼ë²¨ ì œì™¸)"""
        
        # ì œì™¸í•  ì»¬ëŸ¼
        exclude_cols = [
            'frame_id', 'timestamp_ms', 'label_binary', 'label_3class',
            # confidence ì»¬ëŸ¼ì€ í¬í•¨ (ì¤‘ìš” feature)
        ]
        
        # Feature ì»¬ëŸ¼ ì„ íƒ
        feature_cols = [col for col in df.columns if col not in exclude_cols]
        
        return feature_cols
    
    def create_binary_dataset(self, test_size=0.2, val_size=0.1, random_state=42):
        """Binary Classification ë°ì´í„°ì…‹ ìƒì„±"""
        
        print("\n" + "=" * 60)
        print("ğŸ”¹ Binary Classification Dataset")
        print("=" * 60)
        
        # ëª¨ë“  labeled íŒŒì¼ ë¡œë“œ
        labeled_files = sorted(self.labeled_dir.glob("fall-*-labeled.csv"))
        
        all_data = []
        for file in labeled_files:
            df = pd.read_csv(file)
            all_data.append(df)
        
        # ì „ì²´ ë°ì´í„° ë³‘í•©
        df_all = pd.concat(all_data, ignore_index=True)
        
        print(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(df_all)} frames")
        
        # Featureì™€ Label ë¶„ë¦¬
        feature_cols = self.get_feature_columns(df_all)
        X = df_all[feature_cols]
        y = df_all['label_binary']
        
        print(f"ğŸ“Š Features: {len(feature_cols)}ê°œ")
        print(f"ğŸ“Š Label ë¶„í¬:")
        print(y.value_counts())
        
        # Train/Temp split (80/20)
        X_train, X_temp, y_train, y_temp = train_test_split(
            X, y, test_size=test_size, random_state=random_state, stratify=y
        )
        
        # Tempë¥¼ Val/Testë¡œ split (50/50 of temp = 10/10 of total)
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp, y_temp, test_size=0.5, random_state=random_state, stratify=y_temp
        )
        
        # ì €ì¥
        train_df = pd.concat([X_train, y_train], axis=1)
        val_df = pd.concat([X_val, y_val], axis=1)
        test_df = pd.concat([X_test, y_test], axis=1)
        
        train_df.to_csv(self.binary_dir / 'train.csv', index=False)
        val_df.to_csv(self.binary_dir / 'val.csv', index=False)
        test_df.to_csv(self.binary_dir / 'test.csv', index=False)
        
        print(f"\nâœ… Train: {len(train_df)} frames â†’ {self.binary_dir / 'train.csv'}")
        print(f"âœ… Val:   {len(val_df)} frames â†’ {self.binary_dir / 'val.csv'}")
        print(f"âœ… Test:  {len(test_df)} frames â†’ {self.binary_dir / 'test.csv'}")
        
        # í†µê³„
        print(f"\nğŸ“Š Train Label ë¶„í¬:")
        print(y_train.value_counts())
        print(f"\nğŸ“Š Val Label ë¶„í¬:")
        print(y_val.value_counts())
        print(f"\nğŸ“Š Test Label ë¶„í¬:")
        print(y_test.value_counts())
        
        return {
            'train': train_df,
            'val': val_df,
            'test': test_df,
            'feature_cols': feature_cols
        }
    
    def create_3class_dataset(self, test_size=0.2, val_size=0.1, random_state=42):
        """3-Class Classification ë°ì´í„°ì…‹ ìƒì„±"""
        
        print("\n" + "=" * 60)
        print("ğŸ”¹ 3-Class Classification Dataset")
        print("=" * 60)
        
        # ëª¨ë“  labeled íŒŒì¼ ë¡œë“œ
        labeled_files = sorted(self.labeled_dir.glob("fall-*-labeled.csv"))
        
        all_data = []
        for file in labeled_files:
            df = pd.read_csv(file)
            all_data.append(df)
        
        # ì „ì²´ ë°ì´í„° ë³‘í•©
        df_all = pd.concat(all_data, ignore_index=True)
        
        print(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(df_all)} frames")
        
        # Featureì™€ Label ë¶„ë¦¬
        feature_cols = self.get_feature_columns(df_all)
        X = df_all[feature_cols]
        y = df_all['label_3class']
        
        print(f"ğŸ“Š Features: {len(feature_cols)}ê°œ")
        print(f"ğŸ“Š Label ë¶„í¬:")
        print(y.value_counts())
        
        # ëª¨ë“  í´ë˜ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        unique_labels = y.unique()
        if len(unique_labels) < 3:
            print(f"\nâš ï¸  ê²½ê³ : ì¼ë¶€ í´ë˜ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤! ì¡´ì¬í•˜ëŠ” í´ë˜ìŠ¤: {sorted(unique_labels)}")
            print("   ë¼ë²¨ë§ ë¡œì§ì„ í™•ì¸í•˜ê±°ë‚˜ Binary Classificationì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            
            # í´ë˜ìŠ¤ê°€ 2ê°œ ì´ìƒì´ë©´ ê³„ì† ì§„í–‰ (stratify ì—†ì´)
            if len(unique_labels) < 2:
                print("   âŒ í´ë˜ìŠ¤ê°€ 1ê°œë¿ì´ë¯€ë¡œ í•™ìŠµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                return None
        
        # Train/Temp split (80/20)
        try:
            X_train, X_temp, y_train, y_temp = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=y
            )
        except ValueError as e:
            print(f"\nâš ï¸  Stratify ì‹¤íŒ¨: {e}")
            print("   Stratify ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤...")
            X_train, X_temp, y_train, y_temp = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=None
            )
        
        # Tempë¥¼ Val/Testë¡œ split (50/50 of temp = 10/10 of total)
        try:
            X_val, X_test, y_val, y_test = train_test_split(
                X_temp, y_temp, test_size=0.5, random_state=random_state, stratify=y_temp
            )
        except ValueError as e:
            print(f"\nâš ï¸  Stratify ì‹¤íŒ¨: {e}")
            print("   Stratify ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤...")
            X_val, X_test, y_val, y_test = train_test_split(
                X_temp, y_temp, test_size=0.5, random_state=random_state, stratify=None
            )
        
        # ì €ì¥
        train_df = pd.concat([X_train, y_train], axis=1)
        val_df = pd.concat([X_val, y_val], axis=1)
        test_df = pd.concat([X_test, y_test], axis=1)
        
        train_df.to_csv(self.class3_dir / 'train.csv', index=False)
        val_df.to_csv(self.class3_dir / 'val.csv', index=False)
        test_df.to_csv(self.class3_dir / 'test.csv', index=False)
        
        print(f"\nâœ… Train: {len(train_df)} frames â†’ {self.class3_dir / 'train.csv'}")
        print(f"âœ… Val:   {len(val_df)} frames â†’ {self.class3_dir / 'val.csv'}")
        print(f"âœ… Test:  {len(test_df)} frames â†’ {self.class3_dir / 'test.csv'}")
        
        # í†µê³„
        print(f"\nğŸ“Š Train Label ë¶„í¬:")
        print(y_train.value_counts())
        print(f"\nğŸ“Š Val Label ë¶„í¬:")
        print(y_val.value_counts())
        print(f"\nğŸ“Š Test Label ë¶„í¬:")
        print(y_test.value_counts())
        
        return {
            'train': train_df,
            'val': val_df,
            'test': test_df,
            'feature_cols': feature_cols
        }
    
    def save_feature_list(self, feature_cols, dataset_type):
        """Feature ëª©ë¡ ì €ì¥"""
        
        if dataset_type == 'binary':
            output_dir = self.binary_dir
        else:
            output_dir = self.class3_dir
        
        with open(output_dir / 'feature_columns.txt', 'w') as f:
            f.write(f"Total Features: {len(feature_cols)}\n")
            f.write("=" * 60 + "\n\n")
            for i, col in enumerate(feature_cols, 1):
                f.write(f"{i}. {col}\n")
        
        print(f"ğŸ“ Feature ëª©ë¡ ì €ì¥: {output_dir / 'feature_columns.txt'}")
    
    def create_all(self):
        """Binary & 3-Class ë°ì´í„°ì…‹ ëª¨ë‘ ìƒì„±"""
        
        print("=" * 60)
        print("ğŸ“¦ Dataset Creation Pipeline")
        print("=" * 60)
        
        # Binary ë°ì´í„°ì…‹ ìƒì„±
        binary_result = self.create_binary_dataset()
        self.save_feature_list(binary_result['feature_cols'], 'binary')
        
        # 3-Class ë°ì´í„°ì…‹ ìƒì„±
        class3_result = self.create_3class_dataset()
        self.save_feature_list(class3_result['feature_cols'], '3class')
        
        print("\n" + "=" * 60)
        print("âœ… ëª¨ë“  ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
        print("=" * 60)
        print(f"\nğŸ“ Binary Dataset: {self.binary_dir}")
        print(f"   - train.csv")
        print(f"   - val.csv")
        print(f"   - test.csv")
        print(f"   - feature_columns.txt")
        
        print(f"\nğŸ“ 3-Class Dataset: {self.class3_dir}")
        print(f"   - train.csv")
        print(f"   - val.csv")
        print(f"   - test.csv")
        print(f"   - feature_columns.txt")
        
        print("\nğŸš€ ë‹¤ìŒ ë‹¨ê³„: Random Forest ëª¨ë¸ í•™ìŠµ!")


def main():
    # ê²½ë¡œ ì„¤ì •
    labeled_dir = '/home/gjkong/dev_ws/yolo/myproj/labeled'
    output_dir = '/home/gjkong/dev_ws/yolo/myproj/dataset'
    
    # ë°ì´í„°ì…‹ ìƒì„±
    creator = DatasetCreator(labeled_dir, output_dir)
    creator.create_all()


if __name__ == "__main__":
    main()
